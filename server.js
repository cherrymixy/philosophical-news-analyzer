// π‘‡ λ§¨ μ„μ— μ¶”κ°€!
require('dotenv').config();

// ν•„μ”ν• λ¨λ“
const { OpenAI } = require("openai");

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY  // π‘ .envμ—μ„ μ•μ „ν•κ² κ°€μ Έμ΄!
});

// ν…μ¤νΈ μ¶λ ¥ (μ„ νƒ)
console.log("π” API ν‚¤ ν™•μΈ:", process.env.OPENAI_API_KEY);
const express = require('express');
const cors = require('cors');
const fetch = require('node-fetch');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3000;

// λ―Έλ“¤μ›¨μ–΄ μ„¤μ •
app.use(cors());
app.use(express.json());
app.use(express.static('.')); // ν„μ¬ λ””λ ‰ν† λ¦¬μ μ •μ  νμΌ μ κ³µ

// OpenAI API ν”„λ΅μ‹ μ—”λ“ν¬μΈνΈ
app.post('/api/gpt', async (req, res) => {
  try {
    const { messages } = req.body;
    
    if (!messages) {
      return res.status(400).json({ error: 'λ©”μ‹μ§€κ°€ ν•„μ”ν•©λ‹λ‹¤.' });
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: messages,
        max_tokens: 1500,
        temperature: 0.7
      })
    });

    const data = await response.json();
    
    if (!response.ok) {
      console.error('OpenAI API μ—λ¬:', data);
      return res.status(response.status).json({ 
        error: 'OpenAI API νΈμ¶ μ‹¤ν¨', 
        details: data 
      });
    }

    res.json(data);
  } catch (error) {
    console.error('μ„λ²„ μ—λ¬:', error);
    res.status(500).json({ error: 'μ„λ²„ λ‚΄λ¶€ μ¤λ¥' });
  }
});

// μ„λ²„ μ‹μ‘
app.listen(PORT, () => {
  console.log(`μ„λ²„κ°€ http://localhost:${PORT} μ—μ„ μ‹¤ν–‰ μ¤‘μ…λ‹λ‹¤.`);
  console.log('OpenAI API ν‚¤κ°€ μ„¤μ •λμ—λ”μ§€ ν™•μΈν•μ„Έμ”.');
}); 